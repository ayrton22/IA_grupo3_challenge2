{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bees-Wasp_Kris.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPqWwymjfc7n"
      },
      "source": [
        "%%bash\n",
        "mkdir ~/.kaggle\n",
        "mv kaggle.json ~/.kaggle/\n",
        "chmod 600 ~/.kaggle/kaggle.json\n",
        "cat ~/.kaggle/kaggle.json #credenciales de kaggle generadas con la API"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agSdDdeCfyLP"
      },
      "source": [
        "p_base= !kaggle datasets download -d jerzydziewierz/bee-vs-wasp #bajamos de kaggle los datasets de imagenes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjVMvDeWhJQL"
      },
      "source": [
        "!unzip bee-vs-wasp.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61R7G0EuhXV4"
      },
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import regularizers, optimizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o33t_hbxhemo"
      },
      "source": [
        "labels = pd.read_csv(\"kaggle_bee_vs_wasp/labels.csv\", dtype=str)\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-cY8IfCfU9c"
      },
      "source": [
        "duplicados = labels[labels.duplicated()]\n",
        "print(duplicados) #Chequeamos no tener valores duplicados. No tenemos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lC1DGnVinc2"
      },
      "source": [
        "import os\n",
        "labels.path = labels[\"path\"].str.replace(\"\\\\\",\"/\")\n",
        "labels.describe()\n",
        "#reemplazamos la doble barra en el nombre de archivos del dataset de etiquetas porque genera problemas para que flow from dataframe detecte el path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvIxWwp5ByNF"
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_9gckP8BaK7"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.set(style='white',context='notebook')\n",
        "sns.countplot(labels['label'],palette='viridis');\n",
        "\n",
        "plt.title('clases'.title(),fontsize=15);\n",
        "plt.ylabel('count'.title(), fontsize=8)\n",
        "plt.xlabel('seccion'.title(), fontsize=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqG4vmHcOEnf"
      },
      "source": [
        "labels['label'].value_counts(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uN-2h9aVa3Um"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X=labels.drop(columns=['label','id'])\n",
        "y=labels[\"label\"]\n",
        "\n",
        "train, val = train_test_split(labels, test_size=.2, random_state=42)\n",
        "val, test = train_test_split(val, test_size=.5, random_state=42)\n",
        "print('train:', train.shape, '\\nval:', val.shape, '\\ntest',  test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3geGSsJzs7pT"
      },
      "source": [
        "## Probamos un modelo secuencial con data augmentation, regularización y dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UcaV3B3v47L"
      },
      "source": [
        "#chequeamos valores que tenemos en train\n",
        "labels[\"label\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wG2rKoV0QZwh"
      },
      "source": [
        "#generador de imagenes nuevas\n",
        "directory_path=None\n",
        "batch_size=64\n",
        "generador_train = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,)\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = generador_train.flow_from_dataframe(\n",
        "            train,\n",
        "            directory=\"kaggle_bee_vs_wasp/\",\n",
        "            x_col=\"path\",\n",
        "            y_col=\"label\",\n",
        "            has_ext=False,\n",
        "            subset=\"training\",\n",
        "            batch_size=64,\n",
        "            seed=42,\n",
        "            clases=None,\n",
        "            shuffle=True,\n",
        "            class_mode=\"categorical\",\n",
        "            target_size=(150, 150),\n",
        "            color_mode=\"rgb\")\n",
        "\n",
        "validation_generator = val_datagen.flow_from_dataframe(\n",
        "            val,\n",
        "            directory=\"kaggle_bee_vs_wasp/\",\n",
        "            x_col=\"path\",\n",
        "            y_col=\"label\",\n",
        "            has_ext=False,\n",
        "            batch_size=64,\n",
        "            seed=42,\n",
        "            classes=None,\n",
        "            shuffle=False,\n",
        "            class_mode=\"categorical\",\n",
        "            target_size=(150, 150),\n",
        "            color_mode=\"rgb\") \n",
        "\n",
        "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
        "test_g = test_datagen.flow_from_dataframe(test,\n",
        "            directory=\"kaggle_bee_vs_wasp/\",\n",
        "            x_col=\"path\",\n",
        "            y_col='label',\n",
        "            has_ext=False,\n",
        "            target_size=(150, 150),\n",
        "            class_mode=\"categorical\",\n",
        "            classes=None,\n",
        "            batch_size=64,\n",
        "            color_mode=\"rgb\",\n",
        "            seed=42,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuzWbDoccIbZ"
      },
      "source": [
        "classes = list(train_generator.class_indices.keys())\n",
        "classes\n",
        "w = 10\n",
        "h = 10\n",
        "fig = plt.figure(figsize=(10, 15))\n",
        "columns = 4\n",
        "rows = 8\n",
        "ax = []\n",
        "x,y = train_generator.next()\n",
        "for i in range(columns*rows):\n",
        "    image = x[i]\n",
        "    label = classes[list(y[i]).index(1)]\n",
        "    ax.append( fig.add_subplot(rows, columns, i+1) )\n",
        "    ax[-1].set_title(label)\n",
        "    plt.imshow(image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DyGydTN1Z0F"
      },
      "source": [
        "classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko4gy7hFUnOn"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras import regularizers\n",
        "from google.colab import files\n",
        "from keras.models import load_model\n",
        "checkpoint_model3 = ModelCheckpoint('from_scratch/weights.{epoch:02d}-{val_loss:.2f}.h5', monitor='val_accuracy', verbose=0,\n",
        "                             save_best_only=False, save_weights_only=False, mode='auto')\n",
        "\n",
        "#files.download('model3.h5')\n",
        "\n",
        "reduce_lr=ReduceLROnPlateau(monitor='val_loss',patience=3,verbose=1)\n",
        "early_stopping=EarlyStopping(monitor='val_loss',min_delta=0.001,patience=4,restore_best_weights=True,verbose=1)\n",
        "\n",
        "callbacks=[reduce_lr, early_stopping, checkpoint_model3]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKqfMt5_65C1"
      },
      "source": [
        "#Probamos una red con data augmentation + regularización y dropout en la última capa\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras import regularizers\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "dropout_rate=0.3\n",
        "model3 = models.Sequential()\n",
        "model3.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                        input_shape=(150, 150, 3)))\n",
        "model3.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model3.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model3.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model3.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model3.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model3.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model3.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model3.add(layers.Flatten())\n",
        "model3.add(layers.Dense(512, activation='relu',kernel_regularizer=regularizers.l1(0.001)))\n",
        "model3.add(Dropout(dropout_rate))\n",
        "model3.add(layers.Dense(4, activation='softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tf81Xjbd8T1S"
      },
      "source": [
        "model3.summary()\n",
        "model3.save('model3.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9FyqdW88ZKg"
      },
      "source": [
        "model3.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUdgm7gwdd3C"
      },
      "source": [
        "#Antes de fitear vamos a equilibrar las clases \n",
        "from sklearn import preprocessing\n",
        "lb_classes = preprocessing.LabelBinarizer()\n",
        "\n",
        "# Ajustamos a la variable labels\n",
        "lb_classes.fit(labels['label'])\n",
        "lb_classes.classes_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VX7Yl0pIekRd"
      },
      "source": [
        "# Encodeamos las labels\n",
        "labels_ohe = pd.DataFrame(lb_classes.transform(labels['label']), columns=lb_classes.classes_, index=labels['id'])\n",
        "labels_ohe.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "offZp0EEeJOg"
      },
      "source": [
        "class_weight = {k:v for k,v in zip(range(len(lb_classes.classes_)),\n",
        "                                   (1/labels_ohe.iloc[train.index].sum()) * 100)}\n",
        "\n",
        "class_weight"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXNjFBYsfKti"
      },
      "source": [
        "# Visualizamos los pesos definidos\n",
        "((1/labels_ohe.iloc[train.index].sum()) * 100).plot(kind='bar');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Csn_P4QK8lqu"
      },
      "source": [
        "history3 = model3.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=train_generator.n//train_generator.batch_size, #train / batch size. \n",
        "      epochs=85,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=validation_generator.n//validation_generator.batch_size,\n",
        "      class_weight=class_weight,\n",
        "      callbacks=callbacks)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZKRFZwcwt7Q"
      },
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(model3, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET5XcdY8A8fS"
      },
      "source": [
        "files.download('model3.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqSmUqX3WL_2"
      },
      "source": [
        "from keras.models import load_model\n",
        "model3.save('model3.h5')\n",
        "#model3 = load_model('model3.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5diklsW2IPnV"
      },
      "source": [
        "acc3=history3.history['accuracy']\n",
        "val_loss3=history3.history['val_loss']\n",
        "loss3=history3.history['loss']\n",
        "val_acc3=history3.history['val_accuracy']\n",
        "epochs3 = range(1, len(acc3) + 1)\n",
        "\n",
        "plt.figure(figsize=(25,8))\n",
        "plt.title('Modelo de base')\n",
        "plt.plot(epochs3,loss3)\n",
        "plt.plot(epochs3,val_loss3)\n",
        "plt.xticks(ticks=epochs3)\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['Training loss','Validation Loss'])\n",
        "\n",
        "plt.figure(figsize=(25,8))\n",
        "plt.plot(epochs3,acc3)\n",
        "plt.plot(epochs3,val_acc3)\n",
        "plt.xticks(ticks=epochs3)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Training Accuracy','Validation Accuracy']);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfRelA_G1KCb"
      },
      "source": [
        "model3.evaluate(test_g)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tF5Wd39sPTi"
      },
      "source": [
        "##Probamos con VGG19"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLzxoxYlsVaM"
      },
      "source": [
        "from keras.applications import VGG19\n",
        "\n",
        "conv_base = VGG19(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(150, 150, 3))\n",
        "\n",
        "\n",
        "conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhCneFhVsa7h"
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "train_datagen_vgg = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_datagen_vgg = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "batch_size = 20\n",
        "\n",
        "       # Train \n",
        "train_vgg = train_datagen_vgg.flow_from_dataframe(train,\n",
        "            directory=\"kaggle_bee_vs_wasp/\",\n",
        "            x_col=\"path\",\n",
        "            y_col=\"label\",\n",
        "            has_ext=False,\n",
        "            subset=\"training\",\n",
        "            batch_size=batch_size,\n",
        "            classes=None,\n",
        "            seed=42,\n",
        "            shuffle=True,\n",
        "            class_mode=\"categorical\",\n",
        "            target_size=(150, 150))\n",
        "\n",
        "\n",
        "        # Validation generator\n",
        "val_vgg = val_datagen_vgg.flow_from_dataframe(val,\n",
        "            directory=\"kaggle_bee_vs_wasp/\",\n",
        "            x_col=\"path\",\n",
        "            y_col=\"label\",\n",
        "            has_ext=False,\n",
        "            batch_size=batch_size,\n",
        "            seed=42,\n",
        "            classes=None,\n",
        "            shuffle=True,\n",
        "            class_mode=\"categorical\",\n",
        "            target_size=(150, 150))    \n",
        "\n",
        "        # Test\n",
        "test_datagen_vgg=ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "test_vgg = test_datagen_vgg.flow_from_dataframe(test,\n",
        "            directory=\"kaggle_bee_vs_wasp/\",\n",
        "            x_col=\"path\",\n",
        "            y_col='label',\n",
        "            has_ext=False,\n",
        "            target_size=(150, 150),\n",
        "            class_mode=\"categorical\",\n",
        "            classes=None,\n",
        "            batch_size=batch_size,\n",
        "            color_mode=\"rgb\",\n",
        "            seed=42,\n",
        "            shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw71kSsn0y7L"
      },
      "source": [
        "from tensorflow.keras.layers import Input, ZeroPadding2D, Conv2D, BatchNormalization, Activation, MaxPooling2D, GlobalAveragePooling2D, Add, Dense,Flatten\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.initializers import he_normal\n",
        "\n",
        "x_input_vgg = Input(shape=(150, 150, 3))\n",
        "# Instanciamos la base convolucional de VGG19 pre-entrenada en ImageNet\n",
        "vgg19_pretrained = VGG19(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    pooling='avg',\n",
        "    input_shape=((150, 150, 3)),\n",
        ")\n",
        "\n",
        "# Freezamos los pesos de la base convolucional\n",
        "vgg19_pretrained.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xe0RfKm1V75"
      },
      "source": [
        "# La base convolucional procesa los datos de entrada\n",
        "d = vgg19_pretrained(x_input_vgg)\n",
        "d = Dropout(0.5)(d)\n",
        "# La capa densa procesará la salida de la base convolucional y generará las clasificaciones\n",
        "d = Dense(4, activation='softmax', name='ResNet_Bee_Wasp')(d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LEvkGMquOHN"
      },
      "source": [
        "# Instanciamos el modelo\n",
        "vgg19_pretrained = Model(inputs=x_input_vgg, outputs=d, name='VGG19')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WItzhQPp1lPw"
      },
      "source": [
        "# Observamos el summary\n",
        "vgg19_pretrained.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeZJQ_mWsa4a"
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(vgg19_pretrained, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hr9EWyesa0r"
      },
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=5, restore_best_weights=True, verbose=1)\n",
        "# Podemos incorporar este callback al listado anterior y trabajar con ambos a la vez\n",
        "callbacks_list2=[reduce_lr,early_stopping]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN4kbGozul7L"
      },
      "source": [
        "vgg19_pretrained.compile(loss='categorical_crossentropy',optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbCnDAaAurPl"
      },
      "source": [
        "history2 = vgg19_pretrained.fit(train_vgg,\n",
        "      steps_per_epoch=train_vgg.n//train_vgg.batch_size, #train / batch size. \n",
        "      epochs=10,\n",
        "      validation_data=val_vgg,\n",
        "      validation_steps=val_vgg.n//val_vgg.batch_size,\n",
        "      callbacks=callbacks_list2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCIJLllbvX6_"
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(epochs, acc, label='Training acc')\n",
        "plt.plot(epochs, val_acc, label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(epochs, loss, label='Training loss')\n",
        "plt.plot(epochs, val_loss, label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agG0fUE9roE5"
      },
      "source": [
        "##Usamos ResNet50 con imagenet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBMurba_X0_j"
      },
      "source": [
        "#ResNet50\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import utils\n",
        "from keras import optimizers\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras import regularizers\n",
        "from keras.applications import VGG19\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, ZeroPadding2D, Conv2D, BatchNormalization, Activation, MaxPooling2D, GlobalAveragePooling2D, Add, Dense,Flatten\n",
        "from tensorflow.keras.initializers import he_normal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1jt2mwth1D9"
      },
      "source": [
        "x_input = Input(shape=(224, 224, 3)) #definimos el input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2RJ_2e3hyJ_"
      },
      "source": [
        "# Instanciamos la base convolucional de ResNet50 pre-entrenada en ImageNet\n",
        "resnet50_pretrained = ResNet50(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    pooling='avg',\n",
        "    input_shape=((224, 224, 3)),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-_DdH0kWo6N"
      },
      "source": [
        "for layer in resnet50_pretrained.layers:\n",
        "    print(layer.name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kU9Y_ajehv8J"
      },
      "source": [
        "# Freezamos los pesos de la base convolucional\n",
        "resnet50_pretrained.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrjUFITBcxYc"
      },
      "source": [
        "# La base convolucional procesa los datos de entrada\n",
        "x = resnet50_pretrained(x_input)\n",
        "x = Dropout(0.3)(x)\n",
        "# La capa densa procesará la salida de la base convolucional y generará las clasificaciones\n",
        "x = Dense(4, activation='softmax', name='ResNet_Bee_Wasp')(x)\n",
        "\n",
        "# Instanciamos el modelo\n",
        "resnet50_pretrained = Model(inputs=x_input, outputs=x, name='ResNet50')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7EXdH6Nc7H6"
      },
      "source": [
        "# Observamos el summary\n",
        "resnet50_pretrained.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekQ6QTkWc79l"
      },
      "source": [
        "plot_model(resnet50_pretrained, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gb1QgtBmc8IU"
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "\n",
        "train_datagen_resnet = ImageDataGenerator(\n",
        "    # Incluimos el preprocesamiento propio de ResNet50 en nuestro generador\n",
        "    preprocessing_function=preprocess_input,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_datagen_resnet = ImageDataGenerator(preprocessing_function=preprocess_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg8ddVIIc77G"
      },
      "source": [
        "# Creamos la instancias de flow_from_dataframe()\n",
        "\n",
        "train_generator50 = train_datagen_resnet.flow_from_dataframe(train,\n",
        "            directory=\"kaggle_bee_vs_wasp/\",\n",
        "            x_col=\"path\",\n",
        "            y_col=\"label\",\n",
        "            has_ext=False,\n",
        "            subset=\"training\",\n",
        "            batch_size=32,\n",
        "            seed=42,\n",
        "            clases=None,\n",
        "            shuffle=True,\n",
        "            class_mode=\"categorical\",\n",
        "            target_size=(224, 224),\n",
        "            color_mode=\"rgb\")\n",
        "\n",
        "val_generator50 = val_datagen_resnet.flow_from_dataframe(val,\n",
        "            directory=\"kaggle_bee_vs_wasp/\",\n",
        "            x_col=\"path\",\n",
        "            y_col=\"label\",\n",
        "            has_ext=False,\n",
        "            batch_size=32,\n",
        "            seed=42,\n",
        "            classes=None,\n",
        "            shuffle=False,\n",
        "            class_mode=\"categorical\",\n",
        "            target_size=(224, 224),\n",
        "            color_mode=\"rgb\") \n",
        "\n",
        "test_datagen_resnet=ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "test_generator50 = test_datagen_resnet.flow_from_dataframe(test,\n",
        "            directory=\"kaggle_bee_vs_wasp/\",\n",
        "            x_col=\"path\",\n",
        "            y_col='label',\n",
        "            has_ext=False,\n",
        "            target_size=(224, 224),\n",
        "            class_mode=\"categorical\",\n",
        "            classes=None,\n",
        "            batch_size=32,\n",
        "            color_mode=\"rgb\",\n",
        "            seed=42,\n",
        "            shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ea90kYTQdElD"
      },
      "source": [
        "resnet50_pretrained.compile(optimizer='adam',\n",
        "                            loss='categorical_crossentropy',\n",
        "                            metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qX-cXl0dGoU"
      },
      "source": [
        "# Instanciamos nuestro objeto early_stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=10, restore_best_weights=True, verbose=1)\n",
        "\n",
        "# Instanciamos nuestro objeto chekpoint\n",
        "checkpoint = ModelCheckpoint('pretrained/weights.{epoch:02d}-{val_loss:.2f}.h5', monitor='val_loss', verbose=0,\n",
        "                             save_best_only=True, save_weights_only=False, mode='auto')\n",
        "\n",
        "# Definimos una lista de callbacks\n",
        "es = [early_stopping]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-OW6Am5dIMc"
      },
      "source": [
        "# Entrenamos la capa densa de nuestro modelo pre-entrenado\n",
        "history_resnet = resnet50_pretrained.fit(train_generator50,\n",
        "                                  steps_per_epoch=train_generator50.n//train_generator50.batch_size,\n",
        "                                  epochs=30,\n",
        "                                  validation_data=val_generator50,\n",
        "                                  validation_steps=val_generator50.n//val_generator50.batch_size,\n",
        "                                  callbacks=es)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-rSiIm7dIJc"
      },
      "source": [
        "acc_r= history_resnet.history['acc']\n",
        "val_acc_r = history_resnet.history['val_acc']\n",
        "loss_r = history_resnet.history['loss']\n",
        "val_loss_r = history_resnet.history['val_loss']\n",
        "epochs_r = range(1, len(acc_r) + 1)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(epochs_r, acc_r, label='Training acc')\n",
        "plt.plot(epochs_r, val_acc_r, label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(epochs_r, loss_r, label='Training loss')\n",
        "plt.plot(epochs_r, val_loss_r, label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_UOoqkKdIGw"
      },
      "source": [
        "resnet50_pretrained.evaluate(test_generator50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n2A1m-ufRL4"
      },
      "source": [
        "# Predecimos\n",
        "val_pred_resnet = resnet50_pretrained.predict(val_generator50)\n",
        "\n",
        "# Obtenemos la matriz de etiquetas reales de validación\n",
        "val_labels_resnet = lb_classes.transform(val['label'])\n",
        "\n",
        "# Evaluamos las shapes de los arrays resultantes\n",
        "val_pred_resnet.shape, val_labels_resnet.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytuQpIs2weVQ"
      },
      "source": [
        "#generar best_threshold\n",
        "threshold = np.arange(0.1, 0.9, 0.05)\n",
        "\n",
        "# Definimos listas vacíos donde iremos volcando los resultados\n",
        "acc_ = []\n",
        "accs = []\n",
        "best_threshold = np.zeros(val_pred_resnet.shape[1])\n",
        "\n",
        "# Iteramos sobre las distintas clases\n",
        "for i in range(len(best_threshold)):\n",
        "    # Indexamos las probabilidades predichas por clase\n",
        "    y_prob = np.array(val_pred_resnet[:, i])\n",
        "    \n",
        "    # Iteramos sobre los posibles umbrales\n",
        "    for j in threshold:\n",
        "        # Binarizamos las predicciones de acuerdo al umbral\n",
        "        y_pred = [1 if prob >= j else 0 for prob in y_prob]\n",
        "        y_pred = np.array(y_pred)\n",
        "        # Calculamos accuracy\n",
        "        acc = accuracy_score(val_labels_resnet[:, i], y_pred)\n",
        "        acc_.append(acc)\n",
        "    \n",
        "    # Volcamos los resultados en las listas generales\n",
        "    acc_  = np.array(acc_)\n",
        "    index = np.where(acc_==acc_.max())\n",
        "    accs.append(acc_.max())\n",
        "    best_threshold[i] = threshold[index[0][0]]\n",
        "    # Vaciamos la lista de para volver a iterar\n",
        "    acc_ = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbBfO7OtxIN4"
      },
      "source": [
        "accs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtf4-otLxI2t"
      },
      "source": [
        "best_threshold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2mMAKaSxV9j"
      },
      "source": [
        "y_pred_resnet = np.array([[1 if val_pred_resnet[i, j] >= best_threshold[j] else 0 for j in range(val_labels_resnet.shape[1])] for i in range(len(val_labels_resnet))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1nGQw52ACAS"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Definimos listas vacías para ir volcando las métricas por clase\n",
        "accuracy_per_class = []\n",
        "precision_per_class = []\n",
        "recall_per_class = []\n",
        "f1_per_class = []\n",
        "\n",
        "# Definimos un listado de etiquetas de clase\n",
        "classes = list(lb_classes.classes_)\n",
        "\n",
        "for i in range(val_labels_resnet.shape[1]):\n",
        "    # Computamos las métricas de evaluación por clase y hacemos un append a la lista correspondiente\n",
        "    accuracy_per_class.append(accuracy_score(val_labels_resnet[:, i], (val_pred_resnet[:, i] > 0.5).astype(int)).round(2))\n",
        "    precision_per_class.append(precision_score(val_labels_resnet[:,  i], (val_pred_resnet[:, i] > 0.5).astype(int)).round(2))\n",
        "    recall_per_class.append(recall_score(val_labels_resnet[:,  i], (val_pred_resnet[:, i] > 0.5).astype(int)).round(2))\n",
        "    f1_per_class.append(f1_score(val_labels_resnet[:,  i], (val_pred_resnet[:, i] > 0.5).astype(int)).round(2))\n",
        "    \n",
        "    print(classes[i])\n",
        "    print('Accuracy:', accuracy_per_class[i], 'Precision:', precision_per_class[i],\n",
        "          'Recall:', recall_per_class[i], 'F1:', f1_per_class[i])\n",
        "    \n",
        "    # Visualizamos la matriz de confusión por clase\n",
        "    cm  = confusion_matrix(val_labels_resnet[:,  i], (val_pred_resnet[:, i] > 0.5).astype(int))\n",
        "    sns.heatmap(cm, annot=True, cmap='Purples', fmt='.0f', cbar=False, square=True,)\n",
        "    plt.ylabel('Etiqueta real')\n",
        "    plt.xlabel('Etiqueta predicha')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8CybPxNfA0E"
      },
      "source": [
        "# Predecimos\n",
        "\n",
        "test_pred_resnet = resnet50_pretrained.predict(test_generator50)\n",
        "\n",
        "# Tomamos los umbrales óptimos obtenidos en validación para mapear probabilidades a etiquetas de clase\n",
        "y_pred_resnet = np.array([[1 if test_pred_resnet[i, j] >= best_threshold[j] else 0 for j in range(test_pred_resnet.shape[1])] for i in range(len(test_pred_resnet))])\n",
        "\n",
        "# Creamos un DF para facilitar luego la visualización de las predicciones\n",
        "y_pred_resnet = pd.DataFrame(y_pred_resnet, index=test.index)\n",
        "\n",
        "# Evaluamos las shapes de los arrays resultantes\n",
        "y_pred_resnet.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fS9qZZ4VdOYx"
      },
      "source": [
        "import time\n",
        "from IPython.display import clear_output\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "data_dir= \"/content/kaggle_bee_vs_wasp\"\n",
        "\n",
        "n = 50\n",
        "bichos = list()\n",
        "\n",
        "for i in range(n):\n",
        "    random_bichos = np.random.choice(test['path'])\n",
        "    while random_bichos in bichos:\n",
        "        random_bichos = np.random.choice(test['path'])\n",
        "    bichos.append(random_bichos)\n",
        "\n",
        "    # Imagen original\n",
        "    random_bichos_path = os.path.join(data_dir, random_bichos)\n",
        "    test_image = load_img(random_bichos_path, target_size=(224, 224))\n",
        "    test_image = img_to_array(test_image)\n",
        " \n",
        "    # Predicción\n",
        "    prediction = y_pred_resnet.loc[test.loc[test['path'] == random_bichos].index[0]]\n",
        "    predicted_labels = (prediction > 0.5).astype(int)\n",
        "\n",
        "    # Etiquetas\n",
        "    labels = lb_classes.classes_[predicted_labels > 0]\n",
        "\n",
        "    # Visualizamos la imagen y su predicción\n",
        "    title = \"{}\\n Etiquetas reales = {}\\nEtiquetas predichas = {}\" \\\n",
        "                .format(test.loc[test['path'] == random_bichos, 'path'].values[0],\n",
        "                        test.loc[test['path'] == random_bichos, 'label'].values[0],\n",
        "                        labels)\n",
        "\n",
        "    plt.imshow(plt.imread(os.path.join(data_dir, random_bichos)))\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.show();\n",
        "    \n",
        "    if i > 0 and i % 6 == 0:\n",
        "        time.sleep(20)\n",
        "        clear_output(wait=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMHU0jbPW94r"
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "\n",
        "# Path a la imagen\n",
        "img_path = '/content/kaggle_bee_vs_wasp/bee1/10007154554_026417cfd0_n.jpg'\n",
        "\n",
        "# `img` tipo PIL de 224x224\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "\n",
        "# `x`, float32 Numpy array de (224, 224, 3)\n",
        "x = image.img_to_array(img)\n",
        "\n",
        "# Le agregamos una dimesión con np.expand_dims()\n",
        "# para tener un \"batch\" de (1, 224, 224, 3)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "\n",
        "# Aplicamos una normalización por canal\n",
        "x = preprocess_input(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a87QZP9XW-Af"
      },
      "source": [
        "conv5_block3_3_conv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPaP1OtAW9-b"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, classifier_layer_names):\n",
        "    # Primero, creamos un modelo que mapea de una imagen de input a las activaciones\n",
        "    # de la última capa convolucional\n",
        "    last_conv_layer = model.get_layer(last_conv_layer_name)\n",
        "    last_conv_layer_model = models.Model(model.inputs, last_conv_layer.output)\n",
        "\n",
        "    # Segundo, creamos un modelo que mapea las activaciones de la última capa\n",
        "    # convolucional a las predicciones de clase final\n",
        "    classifier_input = layers.Input(shape=last_conv_layer.output.shape[1:])\n",
        "    x = classifier_input\n",
        "    for layer_name in classifier_layer_names:\n",
        "        x = model.get_layer(layer_name)(x)\n",
        "    classifier_model = models.Model(classifier_input, x)\n",
        "\n",
        "    # Luego, computamos el gradiente de la clase con mayor probabilidad para la imagen\n",
        "    # de input con respecto a las activaciones de la última capa convolucional\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Obtenemos las activaciones de la última capa convolucional y la observamos\n",
        "        last_conv_layer_output = last_conv_layer_model(img_array)\n",
        "        tape.watch(last_conv_layer_output)\n",
        "        # Computamos la predicción de clase\n",
        "        preds = classifier_model(last_conv_layer_output)\n",
        "        top_pred_index = tf.argmax(preds[0])\n",
        "        top_class_channel = preds[:, top_pred_index]\n",
        "\n",
        "    # Calculamos el gradiente de la clase predicha con respecto\n",
        "    # a los feature map de salida de la última capa convolucional\n",
        "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
        "\n",
        "    # Vector en que cada elemento es la intensidad media\n",
        "    # del gradiente sobre un canal de feature map específico\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # Multiplicamos cada canal en el feature map por\n",
        "    # \"qué tan importante cada canal es en relación a la clase predicha\"\n",
        "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
        "    pooled_grads = pooled_grads.numpy()\n",
        "    for i in range(pooled_grads.shape[-1]):\n",
        "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
        "\n",
        "    # La media channel-wise del feature map resultante\n",
        "    # es nuestro heatmap de activación de clase\n",
        "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
        "\n",
        "    # A los fines de la visualización, normalizamos el heatmap entre 0 y 1\n",
        "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
        "    return heatmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARJO7Ap4aUQ2"
      },
      "source": [
        "# Imprimimos la clase predicha\n",
        "preds = resnet50_pretrained.predict(x)\n",
        "\n",
        "# Tomamos el feature map de output de la última capa, `block5_conv3` con .get_layer()\n",
        "last_conv_layer_name = 'ResNet_Bee_Wasp'\n",
        "\n",
        "# Definimos un listado de las capas del clasificador\n",
        "classifier_layer_names = [\n",
        "    'input_4',\n",
        "    'resnet50',\n",
        "    'dropout_2',\n",
        "    'ResNet_Bee_Wasp'\n",
        "]\n",
        "\n",
        "# Generamos un heatmap de activación de clase\n",
        "heatmap = make_gradcam_heatmap(x, resnet50_pretrained, last_conv_layer_name, classifier_layer_names)\n",
        "\n",
        "# Display\n",
        "plt.matshow(heatmap);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fez6VGcJcfKa"
      },
      "source": [
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras import backend as K\n",
        "from heatmap import to_heatmap, synset_to_dfs_ids\n",
        "\n",
        "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from heatmap import to_heatmap, synset_to_dfs_ids\n",
        "\n",
        "def display_heatmap(new_model, img_path, ids, preprocessing=None):\n",
        "    # The quality is reduced.\n",
        "    # If you have more than 8GB of RAM, you can try to increase it.\n",
        "    img = image.load_img(img_path, target_size=(800, 1280))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    if preprocessing is not None:\n",
        "        x = preprocess_input(x)\n",
        "\n",
        "    out = new_model.predict(x)\n",
        "\n",
        "    heatmap = out[0]  # Removing batch axis.\n",
        "\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        heatmap = heatmap[ids]\n",
        "        if heatmap.ndim == 3:\n",
        "            heatmap = np.sum(heatmap, axis=0)\n",
        "    else:\n",
        "        heatmap = heatmap[:, :, ids]\n",
        "        if heatmap.ndim == 3:\n",
        "            heatmap = np.sum(heatmap, axis=2)\n",
        "\n",
        "    plt.imshow(heatmap, interpolation=\"none\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "new_model = to_heatmap(resnet50_pretrained)\n",
        "\n",
        "s = '01776313-n'  # Imagenet code for pulga\n",
        "ids = synset_to_dfs_ids(s)\n",
        "display_heatmap(new_model, \"/content/kaggle_bee_vs_wasp/bee1/10007154554_026417cfd0_n.jpg\", ids, preprocess_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcHBpznyf37R"
      },
      "source": [
        "from keras.applications.vgg16 import (preprocess_input, decode_predictions)\n",
        "from keras.preprocessing import image\n",
        "from keras.layers.core import Lambda\n",
        "from keras.models import Sequential\n",
        "from tensorflow.python.framework import ops\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras\n",
        "import sys\n",
        "import cv2\n",
        "\n",
        "def target_category_loss(x, category_index, nb_classes):\n",
        "    return tf.multiply(x, K.one_hot([category_index], nb_classes))\n",
        "\n",
        "def target_category_loss_output_shape(input_shape):\n",
        "    return input_shape\n",
        "\n",
        "def normalize(x):\n",
        "    # utility function to normalize a tensor by its L2 norm\n",
        "    return x / (K.sqrt(K.mean(K.square(x))) + 1e-5)\n",
        "\n",
        "def load_image(path):\n",
        "    img_path = \"/content/kaggle_bee_vs_wasp/bee1/10007154554_026417cfd0_n.jpg\"\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    return x\n",
        "\n",
        "def register_gradient():\n",
        "    if \"GuidedBackProp\" not in ops._gradient_registry._registry:\n",
        "        @ops.RegisterGradient(\"GuidedBackProp\")\n",
        "        def _GuidedBackProp(op, grad):\n",
        "            dtype = op.inputs[0].dtype\n",
        "            return grad * tf.cast(grad > 0., dtype) * \\\n",
        "                tf.cast(op.inputs[0] > 0., dtype)\n",
        "\n",
        "def compile_saliency_function(model, activation_layer='avg_pool'):\n",
        "    input_img = model.input\n",
        "    layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
        "    layer_output = layer_dict[activation_layer].output\n",
        "    max_output = K.max(layer_output, axis=3)\n",
        "    saliency = K.gradients(K.sum(max_output), input_img)[0]\n",
        "    return K.function([input_img, K.learning_phase()], [saliency])\n",
        "\n",
        "def modify_backprop(model, name):\n",
        "    g = tf.get_default_graph()\n",
        "    with g.gradient_override_map({'Relu': name}):\n",
        "\n",
        "        # get layers that have an activation\n",
        "        layer_dict = [layer for layer in model.layers[1:]\n",
        "                      if hasattr(layer, 'activation')]\n",
        "\n",
        "        # replace relu activation\n",
        "        for layer in layer_dict:\n",
        "            if layer.activation == keras.activations.relu:\n",
        "                layer.activation = tf.nn.relu\n",
        "\n",
        "        # re-instanciate a new model\n",
        "        new_model = VGG16(weights='imagenet')\n",
        "    return new_model\n",
        "\n",
        "def deprocess_image(x):\n",
        "    '''\n",
        "    Same normalization as in:\n",
        "    https://github.com/fchollet/keras/blob/master/examples/conv_filter_visualization.py\n",
        "    '''\n",
        "    if np.ndim(x) > 3:\n",
        "        x = np.squeeze(x)\n",
        "    # normalize tensor: center on 0., ensure std is 0.1\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\n",
        "    x *= 0.1\n",
        "\n",
        "    # clip to [0, 1]\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "\n",
        "    # convert to RGB array\n",
        "    x *= 255\n",
        "    if K.image_dim_ordering() == 'th':\n",
        "        x = x.transpose((1, 2, 0))\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "def grad_cam(input_model, image, category_index, layer_name):\n",
        "    model = Sequential()\n",
        "    model.add(input_model)\n",
        "\n",
        "    nb_classes = 1000\n",
        "    target_layer = lambda x: target_category_loss(x, category_index, nb_classes)\n",
        "    model.add(Lambda(target_layer,\n",
        "                     output_shape = target_category_loss_output_shape))\n",
        "\n",
        "    loss = K.sum(model.layers[-1].output)\n",
        "    conv_output =  [l for l in model.layers[0].layers if l.name is layer_name][0].output\n",
        "    grads = normalize(K.gradients(loss, conv_output)[0])\n",
        "    gradient_function = K.function([model.layers[0].input], [conv_output, grads])\n",
        "\n",
        "    output, grads_val = gradient_function([image])\n",
        "    output, grads_val = output[0, :], grads_val[0, :, :, :]\n",
        "\n",
        "    weights = np.mean(grads_val, axis = (0, 1))\n",
        "    cam = np.ones(output.shape[0 : 2], dtype = np.float32)\n",
        "\n",
        "    for i, w in enumerate(weights):\n",
        "        cam += w * output[:, :, i]\n",
        "\n",
        "    cam = cv2.resize(cam, (224, 224))\n",
        "    cam = np.maximum(cam, 0)\n",
        "    heatmap = cam / np.max(cam)\n",
        "\n",
        "    #Return to BGR [0..255] from the preprocessed image\n",
        "    image = image[0, :]\n",
        "    image -= np.min(image)\n",
        "    image = np.minimum(image, 255)\n",
        "\n",
        "    cam = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
        "    cam = np.float32(cam) + np.float32(image)\n",
        "    cam = 255 * cam / np.max(cam)\n",
        "    return np.uint8(cam), heatmap\n",
        "\n",
        "preprocessed_input = load_image(sys.argv[1])\n",
        "\n",
        "\n",
        "predictions = resnet50_pretrained.predict(preprocessed_input)\n",
        "\n",
        "\n",
        "predicted_class = np.argmax(predictions)\n",
        "cam, heatmap = grad_cam(resnet50_pretrained, preprocessed_input, predicted_class, \"block5_conv3\")\n",
        "cv2.imwrite(\"gradcam.jpg\", cam)\n",
        "\n",
        "register_gradient()\n",
        "guided_model = modify_backprop(resnet50_pretrained, 'GuidedBackProp')\n",
        "saliency_fn = compile_saliency_function(guided_model)\n",
        "saliency = saliency_fn([preprocessed_input, 0])\n",
        "gradcam = saliency[0] * heatmap[..., np.newaxis]\n",
        "cv2.imwrite(\"guided_gradcam.jpg\", deprocess_image(gradcam))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}